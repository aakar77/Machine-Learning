{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\n",
      "1794.2212665444993\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as sa\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "'''\n",
    "    FL_DATE is not usefull for regression\n",
    "    ORIGIN_STATE_ABR is duplicated\n",
    "    DEST_STATE_ABR is duplicated\n",
    "    UNIQUE_CARRIER is duplicated of FL_NUM\n",
    "\n",
    "    Question for Aalap : ??\n",
    "    1) ORIGIN, ORIGIN_CITY_NAME, ORIGIN_CITY_MARKET_ID\n",
    "    2) DEST, DEST_CITY_NAME, DEST_CITY_MARKET_ID\n",
    "       \n",
    "    I have included all of the three as categorical variables, I think MARKET ID and ORIGIN CITY name\n",
    "    does not contribute to our cause    \n",
    "    \n",
    "    # For printing the nof of values in each features\n",
    "    # Check the Origin City Market ID and City Values\n",
    "    for val in categorical_list:\n",
    "        print(val,\" : \",df[val].nunique())\n",
    "      \n",
    "'''    \n",
    "# 1) Forming list of attributes headers\n",
    "drop_list = ['FL_DATE', 'FL_NUM','ORIGIN_STATE_ABR','DEST_STATE_ABR', 'UNIQUE_CARRIER', 'ORIGIN_CITY_MARKET_ID', \\\n",
    "                        'DEST_CITY_MARKET_ID']\n",
    "    \n",
    "label_encoding = ['ORIGIN', 'ORIGIN_CITY_NAME', 'DEST', 'DEST_CITY_NAME']\n",
    "\n",
    "categorical_list = ['DAY_OF_WEEK','AIRLINE_ID','DISTANCE_GROUP','ORIGIN','ORIGIN_CITY_NAME','DEST','DEST_CITY_NAME']\n",
    "    \n",
    "real_list = ['CRS_DEP_TIME', 'TAXI_OUT', 'TAXI_IN', 'ACTUAL_ELAPSED_TIME', 'DISTANCE', 'FIRST_DEP_TIME']\n",
    "\n",
    "\n",
    "def preprocess(df):     \n",
    "\n",
    "    df = df.drop('UID', axis = 1)\n",
    "    # dropping the cols in drop_list\n",
    "    for val in drop_list:\n",
    "        df = df.drop(val, axis=1)\n",
    "    \n",
    "    # 3) replacing , in non-categorial data represented in the string\n",
    "    df['DISTANCE'] = df['DISTANCE'].str.replace(',', '')\n",
    "    df['FIRST_DEP_TIME'] = df['DISTANCE'].str.replace(',','')\n",
    "    \n",
    "    # 4) converting the types to numeric & int64\n",
    "    df[real_list] = df[real_list].apply(pd.to_numeric)\n",
    "    \n",
    "    # 5) Scaling the non categorical data\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df[real_list] = min_max_scaler.fit_transform(df[real_list])\n",
    "   \n",
    "    return df\n",
    "    \n",
    "def label_and_dummy_endcoding(df):    \n",
    "    \n",
    "    # 6) label encoding for city and aiarport codes\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    labelencoder = LabelEncoder()\n",
    "    for value in label_encoding:\n",
    "        df[value] = labelencoder.fit_transform(df[value])\n",
    "        #print(value)\n",
    "        #print(df[value])\n",
    "    \n",
    "    # 4) converting the types to numeric\n",
    "    df[categorical_list] = df[categorical_list].astype(int)\n",
    "    \n",
    "    # 7) Dummy encoding for all the categorical features\n",
    "    '''\n",
    "    One hot encoding is not working, beacuse for it, I have to convert all the literals to int\n",
    "    \n",
    "    One difference between both the approaches is: \n",
    "    OneHotEncoding does not work with string values of featurs.\n",
    "    get_dummies() on the contrary works well with strings only\n",
    "    \n",
    "    onehotencoder = OneHotEncoder(categorical_features = categorical_list)\n",
    "    df = onehotencoder.fit_transform(df).toarray()\n",
    "    '''\n",
    "    df = pd.get_dummies(df, columns=categorical_list)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def cal_train_error(predicted, actual):\n",
    "    return((predicted - actual) ** 2).mean(axis=0)\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    print(os.getcwd())\n",
    "    \n",
    "    # data frame for reading input variables\n",
    "    train = pd.read_csv('flights_train.csv', header=0).fillna(value = 0)\n",
    "    test = pd.read_csv('flights_test.csv', header=0)    \n",
    "    \n",
    "    # taking the dependent attribute\n",
    "    delay = (train['ARR_DELAY']).astype(float)    \n",
    "    train = train.drop('ARR_DELAY', axis = 1)\n",
    "\n",
    "    #-----------------------------------------\n",
    "    # Preprocessing and Feature Scaling\n",
    "    #-----------------------------------------\n",
    "    \n",
    "    # preprocessing steps and feature scaling\n",
    "    train = preprocess(train)\n",
    "    test = preprocess(test)\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    # Label and Dummy Encoding\n",
    "    #-----------------------------------------\n",
    "    \n",
    "    # for dummy and label encoding\n",
    "    len_train = len(train)\n",
    "    train_test = pd.concat([train, test])    \n",
    "    train_test = label_and_dummy_endcoding(train_test)\n",
    "    \n",
    "    train, test = train_test.iloc[:len_train, :], train_test.iloc[len_train:,:]\n",
    "\n",
    "    #-----------------------------------------\n",
    "    #Principal Components Analysis\n",
    "    #-----------------------------------------\n",
    "    '''\n",
    "    #perform PCA\\\n",
    "    import sklearn.decomposition as skd\n",
    "    pca = skd.PCA(n_components =10)\n",
    "    val=skd.PCA.fit(pca,train)\n",
    "    W1 = pca.components_\n",
    "    W = W1.transpose()\n",
    "    Z = pca.transform(train)\n",
    "    train = Z\n",
    "    '''\n",
    "    \n",
    "    #---------------------------------\n",
    "    # prediction algorithms\n",
    "    #----------------------------------\n",
    "    \n",
    "    '''\n",
    "    Decision Trees\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    regressor = DecisionTreeRegressor(random_state = 10)\n",
    "    regressor.fit(train, delay)\n",
    "    predicted_val = regressor.predict(train)\n",
    "    print(cal_train_error(predicted_val, delay))\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # Random Forests \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    regressor = RandomForestRegressor(n_estimators = 50, random_state = 0)\n",
    "    regressor.fit(train, delay)\n",
    "    predicted_val = regressor.predict(train)\n",
    "        \n",
    "    print(cal_train_error(predicted_val, delay))\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # Linear Regression\n",
    "    # Getting very high error on the training set = 1626.7158\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(train, delay)\n",
    "    predicted_val = regressor.predict(train)\n",
    "    \n",
    "    print(cal_train_error(predicted_val, delay))\n",
    "    '''\n",
    "    \n",
    "    # KNN algorithm \n",
    "    # KNN is slower than Linear Regression\n",
    "    # for k = 5 error is 1590.17911\n",
    "    # for k = 10 error is 1794.2212665444993\n",
    "    from sklearn.neighbors import KNeighborsRegressor as KNNR\n",
    "    regressor = KNNR(n_neighbors = 10, metric='minkowski', p = 2)\n",
    "    regressor.fit(train, delay)\n",
    "    predicted_val = regressor.predict(train)\n",
    "    print(cal_train_error(predicted_val, delay))\n",
    "    \n",
    "    ''' \n",
    "    for x in zip(predicted_val, delay):\n",
    "        print(x)\n",
    "    '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
